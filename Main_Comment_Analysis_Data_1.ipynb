{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF3+SVOwmdJ+LSaNPuUMrS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahreum239/Test1/blob/main/Main_Comment_Analysis_Data_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "08nKMIW_WS3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import drive\n",
        "import os"
      ],
      "metadata": {
        "id": "simB-wl-Bxi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4hbgpRhBn9S",
        "outputId": "49a26276-ebea-4592-8028-558ba0b263ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the saved data"
      ],
      "metadata": {
        "id": "Ztm0UuTiBxT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "project_dir = '/content/drive/MyDrive/AI Summary Project/Model Free analysis/Comment analysis'\n",
        "sentiment_default = 0.5 # Replace sentiment NA as 0.5\n",
        "\n",
        "# Load JSON data\n",
        "def load_json(filepath):\n",
        "    \"\"\"Load JSON data from a file.\"\"\"\n",
        "    return pd.read_json(filepath, lines=True)"
      ],
      "metadata": {
        "id": "ASHyTceTC-Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The matched videos"
      ],
      "metadata": {
        "id": "7VG_vxPgP48M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Video Matched Data\n",
        "matched_pre_path = f\"{os.path.dirname(project_dir)}/data_before_group.json\"\n",
        "matched_exp_path = f\"{os.path.dirname(project_dir)}/data_before_group_exp.json\"\n",
        "matched = pd.concat([load_json(matched_pre_path), load_json(matched_exp_path)])"
      ],
      "metadata": {
        "id": "mq1iHeNICZiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(matched))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPBT9O0mEFOU",
        "outputId": "fd429ea2-13d9-4242-a76a-c13464098c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matched.groupby('treat').size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZY9Ra7OEj05",
        "outputId": "2c622bca-4487-48d7-c5df-0fbe2ed92dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treat\n",
            "0    2665\n",
            "1    2665\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matched.groupby(['treat']).mid.nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2GIueWfEH2Y",
        "outputId": "836b4806-5292-4acc-ab2d-55ef331ce197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treat\n",
            "0    301\n",
            "1    301\n",
            "Name: mid, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Matched Video Pairs Data\n",
        "pairs_pre_path = f\"{os.path.dirname(project_dir)}/matched_pairs.json\"\n",
        "pairs_exp_path = f\"{os.path.dirname(project_dir)}/matched_pairs_exp.json\"\n",
        "pairsT = pd.concat([load_json(pairs_pre_path), load_json(pairs_exp_path)])"
      ],
      "metadata": {
        "id": "kSw_j7OTlP8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pairsT))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO8yUGCZlud7",
        "outputId": "7b442648-ae8e-433d-f844-92c49af63728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matched.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90uIwNfZD4Dp",
        "outputId": "47bcc3b0-79c9-41ba-82c2-4c5c3c71cd04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mid                                    546195\n",
            "namd                                      老番茄\n",
            "title                              老番茄一秒钟治好鼻炎\n",
            "vid                               T2iSXqiCBLo\n",
            "date                      2023-12-09 00:00:00\n",
            "length                                   1347\n",
            "description    游戏：《瓦力欧制造：超级舞动》\\n这个游戏太抽象了哈哈哈哈哈\n",
            "view_n                                  21384\n",
            "like_n                                    602\n",
            "cmt_n                                      18\n",
            "treat                                       0\n",
            "period                                      6\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pairsT.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S7bTk2Vl84m",
        "outputId": "9f1d3f55-2c92-4f87-92fb-ee9542f540f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yvid                 rwi2zyZUzww\n",
            "bvid                BV1184y1S7c1\n",
            "ratio                   0.976744\n",
            "ytitle    细读经典你管这叫喜剧 开心麻花巅峰之作驴得水\n",
            "btitle     细读经典你管这叫喜剧开心麻花巅峰之作驴得水\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment data"
      ],
      "metadata": {
        "id": "YQUauCyNDlub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Process Comment Data\n",
        "bcmt_path = f\"{project_dir}/bili_sentiment_expT.json\"\n",
        "ycmt_path = f\"{project_dir}/youtube_sentiment_rep_id.json\"\n",
        "bcmt_data = load_json(bcmt_path).fillna({'sentiment': sentiment_default})\n",
        "ycmt_data = load_json(ycmt_path).fillna({'sentiment': sentiment_default})"
      ],
      "metadata": {
        "id": "ZEmtFDd8DhL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bcmt_data.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EndHrkPDxde",
        "outputId": "eeaa5173-051d-4826-f85f-e278e1c34794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reply_id                      195136516640\n",
            "user_name                        我抬手就是一个Z炮\n",
            "sex                                     保密\n",
            "level                                    5\n",
            "content      虚拟主播的演员，一般被叫做“中之人”。内胆这个称呼非常少见\n",
            "time                            1700441095\n",
            "like_num                                12\n",
            "reply_num                              0.0\n",
            "reply_to                               NaN\n",
            "vid                           BV1jw411K7eJ\n",
            "sentiment                         0.619635\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ycmt_data.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqDCoo6yD0bD",
        "outputId": "f391ff37-4cff-4f4b-8336-465f748547f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                   UgzgfJbSMrhCjwZQue54AaABAg\n",
            "type                            topLevelComment\n",
            "channelId              UCSN9fvRC2vzI1H6QCWZDZNg\n",
            "videoId                             hEMzzL8n-Os\n",
            "totalReplyCount                             0.0\n",
            "isPublic                                    1.0\n",
            "textOriginal                            1:44 盜片\n",
            "authorDisplayName              @user-yz9gz4hq3l\n",
            "viewerRating                               none\n",
            "likeCount                                     0\n",
            "publishedAt                2024-01-13T06:53:40Z\n",
            "updatedAt                  2024-01-13T06:53:40Z\n",
            "parentId                                   None\n",
            "sentiment                                   0.5\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matched Videos Only"
      ],
      "metadata": {
        "id": "8to7YhHfXA4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter comments for matched videos only"
      ],
      "metadata": {
        "id": "UrHS6HEGU_ZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Filter comments for matched videos only.\"\"\"\n",
        "def filter_comments_for_videos(df, video_column, video_ids):\n",
        "    # Function to filter comments for matched videos only\n",
        "    return df[df[video_column].isin(video_ids)]"
      ],
      "metadata": {
        "id": "tMdh14qEVPUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter comments for matched videos only\n",
        "y_videos = matched[matched['treat'] == 0]['vid'].unique()\n",
        "b_videos = matched[matched['treat'] == 1]['vid'].unique()\n",
        "ycmt_filtered = filter_comments_for_videos(ycmt_data, 'videoId', y_videos)\n",
        "bcmt_filtered = filter_comments_for_videos(bcmt_data, 'vid', b_videos)"
      ],
      "metadata": {
        "id": "bCUl6PTpTY8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ycmt_filtered))\n",
        "print(len(bcmt_filtered))\n",
        "\n",
        "# Not all videos (n=2665) has comment data\n",
        "print((ycmt_filtered.videoId.nunique()))\n",
        "print((bcmt_filtered.vid.nunique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH9h-UJmiu52",
        "outputId": "53feaae3-32a4-4342-84ae-bdeffa9bfc46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103392\n",
            "1664616\n",
            "2312\n",
            "2651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter by Time Window"
      ],
      "metadata": {
        "id": "zk0lAAQLW4AD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "min_date, max_date = '2023-09-04', '2023-12-10'\n",
        "\n",
        "def convert_to_datetime(df, column, time_format=None, unit=None):\n",
        "    # Convert timestamps to datetime with UTC\n",
        "    df[column] = pd.to_datetime(df[column], format=time_format, unit=unit, utc=True)\n",
        "\n",
        "def filter_time_window(df, date_col, start=min_date, end=max_date):\n",
        "    \"\"\"Filter DataFrame by date range.\"\"\"\n",
        "    df.loc[:, 'cmt_date'] = df[date_col].dt.strftime('%Y-%m-%d')\n",
        "    return df[(df['cmt_date'] >= start) & (df['cmt_date'] <= end)]\n",
        "\n",
        "# Process ycmt and bcmt DataFrames\n",
        "def filter_comments_for_times(ycmt, bcmt):\n",
        "\n",
        "    # Convert timestamps to datetime with appropriate formats\n",
        "    convert_to_datetime(ycmt, 'publishedAt', time_format='%Y-%m-%dT%H:%M:%SZ')\n",
        "    convert_to_datetime(bcmt, 'time', unit='s')\n",
        "\n",
        "    # Rename datetime columns for consistency\n",
        "    ycmt.rename(columns={'publishedAt': 'cmt_timestamp'}, inplace=True)\n",
        "    bcmt.rename(columns={'time': 'cmt_timestamp'}, inplace=True)\n",
        "\n",
        "    # Filter by date range and add period column\n",
        "    ycmt = filter_time_window(ycmt, 'cmt_timestamp')\n",
        "    bcmt = filter_time_window(bcmt, 'cmt_timestamp')\n",
        "\n",
        "    return ycmt, bcmt"
      ],
      "metadata": {
        "id": "-Af5WcFpb8gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the processing function\n",
        "ycmt, bcmt = filter_comments_for_times(ycmt_filtered, bcmt_filtered)"
      ],
      "metadata": {
        "id": "U7_N7d7xcCIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Period Variable"
      ],
      "metadata": {
        "id": "2_PaCkPFVp72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Add period columns based on weekly intervals.\"\"\"\n",
        "\n",
        "def make_timezone_naive(df, timestamp_column):\n",
        "    # Convert timestamp columns to timezone-naive (removing timezone information)\n",
        "    df[timestamp_column] = df[timestamp_column].dt.tz_convert(None)\n",
        "\n",
        "def calculate_period(date):\n",
        "    # Extract week number in the format 'YYYY-WW' and adjust based on starting period\n",
        "    iso_week = date.strftime('%G-%V')\n",
        "    return int(iso_week[-2:]) - 43\n",
        "\n",
        "def add_period_column(df, timestamp_column):\n",
        "    # Add 'period' column based on weekly intervals\n",
        "    df.loc[:, 'period'] = df[timestamp_column].dt.to_period('W').apply(lambda x: calculate_period(x.start_time))\n",
        "\n",
        "# Process ycmt and bcmt DataFrames\n",
        "def process_comments(ycmt, bcmt):\n",
        "\n",
        "    for df in [ycmt, bcmt]:\n",
        "        make_timezone_naive(df, 'cmt_timestamp')\n",
        "        add_period_column(df, 'cmt_timestamp')\n",
        "\n",
        "    return ycmt, bcmt"
      ],
      "metadata": {
        "id": "BW_JHedFU_t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the processing function\n",
        "ycmt_pr, bcmt_pr = process_comments(ycmt, bcmt)"
      ],
      "metadata": {
        "id": "NH1LqaGORzhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ycmt_filtered))\n",
        "print(len(bcmt_filtered))\n",
        "\n",
        "# Not all videos (n=2665) has comment data within limited time window\n",
        "print((ycmt_pr.videoId.nunique()))\n",
        "print((bcmt_pr.vid.nunique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHZffJ45jUIy",
        "outputId": "6d551777-c491-41af-fd9d-336dea5767d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103392\n",
            "1664616\n",
            "2173\n",
            "2550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concat Data at Comment-Video Level"
      ],
      "metadata": {
        "id": "x-wppxKdiQxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define selected columns and standardized column names for YouTube and Bilibili data\n",
        "selected_columns = {\n",
        "    \"bilibili\": ['reply_id', 'vid', 'user_name', 'like_num', 'reply_num', 'sentiment', 'content', 'cmt_timestamp', 'period'],\n",
        "    \"youtube\": ['id', 'videoId', 'authorDisplayName', 'likeCount', 'totalReplyCount', 'sentiment', 'textOriginal', 'cmt_timestamp', 'period']\n",
        "}\n",
        "standard_columns = ['commentid', 'vid', 'cmt_user', 'cmt_likes', 'cmt_replies', 'sentiment', 'comment', 'cmt_timestamp', 'period']\n",
        "\n",
        "# Create DataFrames with standardized columns\n",
        "bcmt_df = bcmt_pr[selected_columns[\"bilibili\"]].copy()\n",
        "ycmt_df = ycmt_pr[selected_columns[\"youtube\"]].copy()\n",
        "bcmt_df.columns = ycmt_df.columns = standard_columns\n",
        "\n",
        "# Assign treatment indicator: 1 for Bilibili, 0 for YouTube\n",
        "bcmt_df['treat'] = 1\n",
        "ycmt_df['treat'] = 0\n",
        "\n",
        "# Concatenate both DataFrames into a single DataFrame\n",
        "cmt_df = pd.concat([bcmt_df, ycmt_df], ignore_index=True)\n",
        "\n",
        "# channel_id (mid)\n",
        "mid_vid = matched[['mid','vid']].drop_duplicates()\n",
        "cmt_df = pd.merge(cmt_df, mid_vid, on='vid', how='left')\n",
        "\n",
        "# Timestamp\n",
        "vid_timestamp = matched[['vid','period']]\n",
        "vid_timestamp.columns = ['vid','vd_period']\n",
        "cmt_df = pd.merge(cmt_df, vid_timestamp, on='vid', how='left')"
      ],
      "metadata": {
        "id": "rsLTyY3Gmhko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filters for videos that are present in both YouTube and Bilibili datasets\n",
        "common_videos = pairsT[pairsT['yvid'].isin(ycmt_df['vid']) & pairsT['bvid'].isin(bcmt_df['vid'])]\n",
        "common_yvids = common_videos['yvid']\n",
        "common_bvids = common_videos['bvid']\n",
        "\n",
        "# Filter for common video records and drop rows with missing comments\n",
        "cmt_df_pr = cmt_df[cmt_df['vid'].isin(common_yvids) | cmt_df['vid'].isin(common_bvids)]\n",
        "\n",
        "# Drop records with missing comments\n",
        "cmt_df_pr = cmt_df_pr.dropna(subset=['comment'])"
      ],
      "metadata": {
        "id": "HsvlNcpjmfFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique videos per treatment group\n",
        "print(cmt_df.groupby('treat')['vid'].nunique().reset_index(name='unique_videos'))\n",
        "print(cmt_df_pr.groupby('treat')['vid'].nunique().reset_index(name='unique_videos'))\n",
        "\n",
        "# Unique channels per treatment group\n",
        "print(cmt_df.groupby('treat')['mid'].nunique().reset_index(name='unique_channels'))\n",
        "print(cmt_df_pr.groupby('treat')['mid'].nunique().reset_index(name='unique_channels'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1opwt5U-kE3j",
        "outputId": "843bb4d4-6a5a-4e04-eb8d-4a0422ec77bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   treat  unique_videos\n",
            "0      0           2173\n",
            "1      1           2550\n",
            "   treat  unique_videos\n",
            "0      0           2162\n",
            "1      1           2162\n",
            "   treat  unique_channels\n",
            "0      0              281\n",
            "1      1              298\n",
            "   treat  unique_channels\n",
            "0      0              281\n",
            "1      1              281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4oYRlIdOnWqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_sentiment_categories(df, sentiment_col='sentiment'):\n",
        "    \"\"\"Add sentiment categories based on sentiment score.\"\"\"\n",
        "    df['pos_cmt'] = (df[sentiment_col] >= 0.6).astype(int)\n",
        "    df['neg_cmt'] = (df[sentiment_col] <= 0.4).astype(int)\n",
        "    df['neu_cmt'] = ((df[sentiment_col] > 0.4) & (df[sentiment_col] < 0.6)).astype(int)\n",
        "    return df"
      ],
      "metadata": {
        "id": "T2wpt0HinW7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmt_df_pr = apply_sentiment_categories(cmt_df_pr, sentiment_col='sentiment')"
      ],
      "metadata": {
        "id": "6zXczdiVoiNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cmt_df_pr.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMZOtUfdj2xZ",
        "outputId": "507d7208-b999-461b-e3bc-3ebc53eee896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "commentid                                    193843602800\n",
            "vid                                          BV1sj411a77r\n",
            "cmt_user                                         awiwicat\n",
            "cmt_likes                                              56\n",
            "cmt_replies                                           1.0\n",
            "sentiment                                        0.527836\n",
            "comment          哇塞，一分钟我就刷新了，这种老恐怖片有种年代的单调平实感觉，这种程度都吓不到人了\n",
            "cmt_timestamp                         2023-11-10 14:45:01\n",
            "period                                                  2\n",
            "treat                                                   1\n",
            "mid                                               2390247\n",
            "vd_period                                               2\n",
            "pos_cmt                                                 0\n",
            "neg_cmt                                                 0\n",
            "neu_cmt                                                 1\n",
            "Name: 85, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handle Outliers"
      ],
      "metadata": {
        "id": "LjqRQ68Njl-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_channels_by_upload_frequency(df, min_weeks=5):\n",
        "    \"\"\"Filter for channels with a minimum video upload frequency.\"\"\"\n",
        "    channel_counts = (\n",
        "        df.groupby(['treat', 'mid'])['vd_period']\n",
        "        .nunique()\n",
        "        .reset_index(name='vd_count')\n",
        "    )\n",
        "    return channel_counts[channel_counts['vd_count'] >= min_weeks]\n",
        "\n",
        "def filter_channels_present_on_both_platforms(df, valid_mids):\n",
        "    \"\"\"Ensure channels are present on both platforms (YouTube and Bilibili).\"\"\"\n",
        "    filtered_df = valid_mids.copy()\n",
        "    platform_check = (\n",
        "        filtered_df.groupby('mid')\n",
        "        .filter(lambda x: x['treat'].nunique() == 2)['mid']\n",
        "        .unique()\n",
        "    )\n",
        "    return df[df['mid'].isin(platform_check)]\n",
        "\n",
        "def filter_for_period_existence(df, period_column='vd_period'):\n",
        "    \"\"\"Ensure both 'before' and 'after' periods exist for each channel-platform pair.\"\"\"\n",
        "    df['after'] = (df[period_column] >= 0).astype(int)\n",
        "    period_counts = df.groupby(['treat', 'mid', 'after']).size().unstack(fill_value=0)\n",
        "    valid_pairs = period_counts[(period_counts[0] > 0) & (period_counts[1] > 0)].index\n",
        "    return df[df.set_index(['treat', 'mid']).index.isin(valid_pairs)]"
      ],
      "metadata": {
        "id": "OSQb41Jqph24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_high_discrepancy_mids(matchedT, valid_mids, cmt_text_df, discrepancy_threshold=5):\n",
        "    \"\"\"\n",
        "    Filters out 'mid' values with high discrepancies in user engagement metrics (view_n) between treatment groups.\n",
        "    \"\"\"\n",
        "    filtered_T = matchedT[matchedT.mid.isin(valid_mids.mid.unique())]\n",
        "\n",
        "    comparison = (\n",
        "        filtered_T\n",
        "        .groupby(['treat', 'mid'])\n",
        "        .agg({'view_n': 'mean'})  # Add other metrics as needed (e.g., 'like_n', 'cmt_n', 'length')\n",
        "        .reset_index()\n",
        "    )\n",
        "    comparison_pivot = comparison.pivot(index='mid', columns='treat', values=['view_n'])\n",
        "    comparison_pivot.columns = [f'{metric}_treat{treat}' for metric, treat in comparison_pivot.columns] # Flatten the column MultiIndex\n",
        "    comparison_pivot['view_diff'] = (comparison_pivot['view_n_treat1'] - comparison_pivot['view_n_treat0']).abs() # Calculate the absolute discrepancies\n",
        "    avg_view_diff = comparison_pivot['view_diff'].mean()\n",
        "\n",
        "    # Filter out these high-discrepancy mids from the main DataFrame\n",
        "    discrepant_mids = comparison_pivot[\n",
        "        (comparison_pivot['view_diff'] > avg_view_diff * discrepancy_threshold)\n",
        "    ].index.tolist()\n",
        "\n",
        "    filtered_cmt_text_df = cmt_text_df[~cmt_text_df.mid.isin(discrepant_mids)]\n",
        "    return filtered_cmt_text_df"
      ],
      "metadata": {
        "id": "-t4BCfClsbkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_mids = filter_channels_by_upload_frequency(cmt_df_pr)\n",
        "\n",
        "cmt_df1 = filter_channels_present_on_both_platforms(cmt_df_pr, valid_mids)\n",
        "cmt_df2 = filter_for_period_existence(cmt_df1)\n",
        "cmt_df3 = filter_high_discrepancy_mids(matched, valid_mids, cmt_df2, discrepancy_threshold=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpfPdhaJp7Qo",
        "outputId": "f2ca7603-c504-46f2-dbae-5a614a94bda1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-260-036a5c9fa601>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['after'] = (df[period_column] >= 0).astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugging information\n",
        "print(f\"Initial merged DataFrame length: {len(cmt_df_pr)}\")\n",
        "print(f\"Filtered channels_present_on_both_platforms: {len(cmt_df1)}\")\n",
        "print(f\"Filtered for_period_existence: {len(cmt_df2)}\")\n",
        "print(f\"Final filter_high_discrepancy_mids: {len(cmt_df3)}\")\n",
        "\n",
        "print(f\"Unique video IDs in filtered DataFrame: {len(cmt_df3['vid'].unique())}\")\n",
        "print(f\"Unique mids by treatment after filtering: {cmt_df3.groupby('treat')['mid'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES1IFkt1uJjz",
        "outputId": "ec94f733-b948-4e4d-8bbf-58374ac2391d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial merged DataFrame length: 1467956\n",
            "Filtered channels_present_on_both_platforms: 1167642\n",
            "Filtered for_period_existence: 1141127\n",
            "Final filter_high_discrepancy_mids: 1105360\n",
            "Unique video IDs in filtered DataFrame: 3324\n",
            "Unique mids by treatment after filtering: treat\n",
            "0    127\n",
            "1    128\n",
            "Name: mid, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cmt_df3.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpn8_95diWYO",
        "outputId": "49866400-0dfa-4a76-c22c-82a9cf671e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "commentid               196719582208\n",
            "vid                     BV1Je411Z7ti\n",
            "cmt_user                      涛子先生先生\n",
            "cmt_likes                        964\n",
            "cmt_replies                     49.0\n",
            "sentiment                   0.494229\n",
            "comment                      我这样不香吗？\n",
            "cmt_timestamp    2023-12-01 10:50:05\n",
            "period                             5\n",
            "treat                              1\n",
            "mid                         27899754\n",
            "vd_period                          5\n",
            "pos_cmt                            0\n",
            "neg_cmt                            0\n",
            "neu_cmt                            1\n",
            "after                              1\n",
            "Name: 277, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save JSON data"
      ],
      "metadata": {
        "id": "rkDYuImGXTyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Refer https://colab.research.google.com/drive/1NkpEjRs081qCUV4agH_QQ4iqgwPOa6Ql#scrollTo=nxvBzhq_-b1Y\n",
        "# # Export the list to a JSON file\n",
        "# with open('cmt_text_df_filtered.json', 'w') as f:\n",
        "#     # Convert the DataFrame to a JSON-serializable format (e.g., dictionary)\n",
        "#     json.dump(cmt_df3.to_dict(orient='records'), f, default=str) # Added default=str to handle Timestamp objects"
      ],
      "metadata": {
        "id": "2UmCUOHEXT_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}